# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DMtfIhDfGDtNd8ynd7T7XDVJXoik6NVk
"""

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
nltk.download('punkt')
nltk.download('stopwords')

data = pd.read_csv('chrome_reviews.csv')

data.head(1)

data.shape

cols = ['ID','Review URL','Thumbs Up','User Name','Developer Reply','Version','Review Date','App ID']

data.drop(cols, axis=1, inplace=True)

data.head()

data['Star'].value_counts()

data.dropna(inplace=True)
data = data[data['Star']!=3]
data['label'] = np.where(data['Star']>3,1,0)
data.drop('Star', axis=1, inplace=True)
data.head()

data.shape

data['label'].value_counts()

stop_words = set(stopwords.words('english'))
stop_words.remove('not')
stop_words.remove('nor')

ps = PorterStemmer()
def clean_text(text):
  text = re.sub('[^A-Za-z]',' ',text)
  text = text.lower()
  word = nltk.word_tokenize(text)
  word = [ps.stem(j) for j in word if j not in stop_words]
  return (' '.join(word))

cl_text = [clean_text(i) for i in data['Text']]

data['clean_text'] = cl_text
data.drop('Text', axis=1, inplace=True)

data.head()

data.shape

data.isnull().any()

X = data['clean_text']
y = data['label']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)

print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

one_per_tr = (np.sum(y_train==1) / len(y_train))*100
zero_per_tr = (np.sum(y_train==0) / len(y_train))*100
one_per_te = (np.sum(y_test==1) / len(y_test))*100
zero_per_te = (np.sum(y_test==0) / len(y_test))*100

print('{}% 1 and {}% 0 is in train dataset'.format(one_per_tr, zero_per_tr))
print('{}% 1 and {}% 0 is in test dataset'.format(one_per_te, zero_per_te))

tf_idf = TfidfVectorizer(max_features=2000, min_df=2, ngram_range=(1,2))
tf_idf.fit(X_train)
X_train_tfidf = tf_idf.fit_transform(X_train)
X_test_tfidf = tf_idf.transform(X_test)

pickle.dump(tf_idf.vocabulary_,open('tfidf.pkl','wb'))

X_train_tfidf.shape

X_test_tfidf.shape

from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier

"""### Naive Bayes"""

param_nb = {'alpha' : [0.01,0.1,1,10]}
model_nb = MultinomialNB()
clf_nb = GridSearchCV(model_nb, param_nb, cv=5 ,return_train_score=True)
clf_nb.fit(X_train_tfidf, y_train)

y_pred_tr = clf_nb.predict(X_train_tfidf)
y_pred_te = clf_nb.predict(X_test_tfidf)

cm_tr = confusion_matrix(y_train, y_pred_tr)
acc_tr = accuracy_score(y_train, y_pred_tr)

cm_te = confusion_matrix(y_test, y_pred_te)
acc_te = accuracy_score(y_test, y_pred_te)
print('Train confusion matrix: ')
print(cm_tr)
print('Test confusion matrix: ')
print(cm_te)
print('Train accuracy: ',acc_tr,' Testaccuracy: ',acc_te)

clf_nb.best_params_

"""### KNN"""

param_knn = {'n_neighbors' : [1,5,10,20,50]}
model_knn = KNeighborsClassifier()
clf_knn = GridSearchCV(model_knn, param_knn, cv=5 ,return_train_score=True)
clf_knn.fit(X_train_tfidf, y_train)

y_pred_tr = clf_knn.predict(X_train_tfidf)
y_pred_te = clf_knn.predict(X_test_tfidf)

cm_tr = confusion_matrix(y_train, y_pred_tr)
acc_tr = accuracy_score(y_train, y_pred_tr)

cm_te = confusion_matrix(y_test, y_pred_te)
acc_te = accuracy_score(y_test, y_pred_te)
print('Train confusion matrix: ')
print(cm_tr)
print('Test confusion matrix: ')
print(cm_te)
print('Train accuracy: ',acc_tr,' Testaccuracy: ',acc_te)

"""### Logistic Regression"""

param_lr = {'C' : [0.0001, 0.001, 0.01,0.1,1,10,100]}
model_lr = LogisticRegression()
clf_lr = GridSearchCV(model_lr, param_lr, cv=5 ,return_train_score=True)
clf_lr.fit(X_train_tfidf, y_train)

y_pred_tr = clf_lr.predict(X_train_tfidf)
y_pred_te = clf_lr.predict(X_test_tfidf)

cm_tr = confusion_matrix(y_train, y_pred_tr)
acc_tr = accuracy_score(y_train, y_pred_tr)

cm_te = confusion_matrix(y_test, y_pred_te)
acc_te = accuracy_score(y_test, y_pred_te)
print('Train confusion matrix: ')
print(cm_tr)
print('Test confusion matrix: ')
print(cm_te)
print('Train accuracy: ',acc_tr,' Testaccuracy: ',acc_te)

"""### SVC"""

param_svm = {'alpha' : [0.0001, 0.001, 0.01,0.1,1]}
model_svm = SGDClassifier(loss='hinge')
clf_svm = GridSearchCV(model_svm, param_svm, cv=5 ,return_train_score=True)
clf_svm.fit(X_train_tfidf, y_train)

y_pred_tr = clf_svm.predict(X_train_tfidf)
y_pred_te = clf_svm.predict(X_test_tfidf)

cm_tr = confusion_matrix(y_train, y_pred_tr)
acc_tr = accuracy_score(y_train, y_pred_tr)

cm_te = confusion_matrix(y_test, y_pred_te)
acc_te = accuracy_score(y_test, y_pred_te)
print('Train confusion matrix: ')
print(cm_tr)
print('Test confusion matrix: ')
print(cm_te)
print('Train accuracy: ',acc_tr,' Testaccuracy: ',acc_te)

"""# Naive Bayes classifier with alpha=1 is best classifier"""

import pickle

model = MultinomialNB(alpha=1)
model.fit(X_train_tfidf.toarray(), y_train)

pickle.dump(model, open('model.pkl','wb'))

model = pickle.load(open('model.pkl','rb'))

tfidf = TfidfVectorizer(vocabulary=pickle.load(open("tfidf.pkl", "rb")))

transformer = TfidfTransformer()

temp = transformer.fit_transform(tfidf.fit_transform(["aaa ccc eee"]))

temp.toarray().shape

model.predict(temp)[0]

